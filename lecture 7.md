# lecture 7

# memory management

- a program must be brought from disk into main memory and loaded within a process for it to be run
    - **executable code** (compiled) or **source code** (interpreted)
    - recall that a process is a program in execution
- **main memory/registers** are storage that CPU can directly access
    - **register** can be accessed in one CPU clock cycle
    - a **main memory** access can take many cycles
    - **cache** sits between main memory and CPU registers to improve memory access time
- how can we protect memory to ensure correct operation?
    - writing into the memory of another user must not be allowed
    - accidentally writing into memory of your other processes or program code of current process should be avoided
    

## access binding to memory

- binding of address refers to the procedure of translating an address in the compiled program code to a memory address when the program is run
- address binding of instructions and data to memory can happen at three different stages
    
| binding time | description |
| --- | --- |
| compile time | if memory location is known ahead, generate absolute code-- code must be recompiled if starting location changes |
| load time | if memory location is not known at compile time, relocatable code must be generated-- addresses are defined after the program is loaded |
| execution time | if a process can be moved during execution from one memory segment to another, binding must be delayed until run time-- hardware support for dynamic address mapping (e.g., base and limit registers) is required |

- for each process, there is a **pair of base and limit registers** that define the address space of the process
    - an address generated should stay between base and base+limit
    - access to an address beyond the allocated address space is invalid
    - this protects a process from accessing the content of another process

```c
#include <stdio.h>
int main() {
int number;
	printf("Please enter data: ");
	scanf("%d", number);
	printf("Your data is %d\n", number);
}

```

## logic and physical address

- memory management technique is required to support run-time address-binding— this is because a program may move around during execution
- the key idea behind memory management is the separation of logical address and physical address

- logical address is the address generated by the CPU, e.g. **an instruction refers to an integer stored at a particular address** — this is also called a virtual address when it is different from the physical address

- physical address is the address sent to the main memory
- the logical and physical addresses are the same in both compile-time and load-time address-binding schemes, but the logical and physical addresses differ in run-time address-binding scheme
    - only the translation from virtual to physical address needs to be **changed** when a program moves around

## memory management unit

- each virtual address must be mapped or translated into a physical address in run-time binding scheme and this occurs once to fetch an instruction and once to fetch each operand
- this translation must be very fast and efficient, so it must be done by **hardware**
- the hardware device that maps virtual to physical address is called **memory management unit** or MMU
    - in the simplest MMU solution, the value in a special relocation register is added to every logical address generated by a user process to form the physical address when it is sent to memory— the **relocation register is like the base register**
- user process only deals with logical addresses; it never sees the real physical addresses

## memory allocation

- main memory is usually divided into two partitions
    - resident OS is usually stored in **low memory**, together with interrupt vector and interrupt handlers
    - user processes are stored in **high memory**
- memory allocation is concerned with where a user process is actually placed when it is swapped/moved into main memory
- we assume that the whole process will be stored in the main memory for it to be executed
    - **contiguous allocation**: allocate a single block of memory of size sufficient to hold the process
    - **non-contiguous allocation**: chop up the process and allocate multiple blocks of memory to hold the process— the two major schemes are **paging and segmentation**

# contiguous allocation

- the most straightforward solution is to allocate a single block of memory to hold a process
    - one single block to hold one process (single partition)
    - multiple blocks to hold multiple processes (multiple partition)
- a **pair of registers** are used to protect user processes from accidentally stepping into each other and changing operating system code and data
  
    
    | the relocation register contains the value of smallest physical address for the process |
    | --- |
    | the limit register contains the range (size) of logical address space |
    | each logical address must be less than the limit register |
    | MMU maps logical address dynamically into physical address by adding it to the relocation register |


## multiple fixed partition

- this was used by one of the earliest and classical OS, IBM MVS, forty years ago
    - **MFT**: multiprogramming with a fixed number of tasks
- divide the memory into several partitions— when a partition is free, a job is selected to be loaded into the partition
- only at most n jobs can be executed if there are n partitions
- very simple to manage but not effective if there are many small jobs since many partitions are only used tom very small degree and total free memory is still quite large

## multiple variable partition

- commonly used in IBM MVS
    - **MVT**: multiprogramming with a variable number of tasks
- a block of available memory is called a **hole**— holes of various sizes are scattered throughout the memory
- when a process arrives, it is allocated memory from a hole large enough to accommodate it
- OS maintains information about allocated partitions and free partitions (i.e. holes), often in the form of **linked lists**

### example

- memory of 256K with OS consuming first 40K
    - fixed partitions of size 80K, 100K and 36K for MFT
    - no restriction for MVT

| process | memory needed | process time  |
| --- | --- | --- |
| P1 | 60k | 10 |
| P2 | 100k | 5 |
| P3 | 70k | 10 |
| P4 | 40k | 20 |
| P5 | 50k | 15 |

## MFT
- not large enough for P4 or P5

## MVT
- could admit P4
- when a request for memory allocation arrives and if there are m holes available, which hole is to be used for the request?

| first-fit | allocate the first hole that is big enough |
| --- | --- |
| best-fit | allocate the smallest hole that is big enough

produce the smallest leftover hole

do not waste large holes for future large job |
| worst-fit | allocate the largest hole

produce the largest leftover hole

ensure that leftover holes are large enough to be useful |
- best-and worst-fit need to maintain a sorted list for sizes of holes or a search is needed
    - first-and best-fit are normally performing better than worst-fit

### example

- requests of 212, 417, 112, 426 arrive in that order, for the following configuration
- worst fit is better in this case— if two requests each of 250 come:

## fragmentation
- fragmentation means that memory is available, but somehow could not be used

### external fragmentation
- total memory space exists to satisfy a request but it is not contiguous that it could not be used
- it is a **wastage outside partition**

### internal fragmentation
- memory internal to partition is not used (**wastage inside partition**)
- this happens when a hole is slightly larger than requested size that the overhead to manage the small hole is not justified

### reduce external fragmentation by compaction
- move memory content around to place all small free memory holes together to create one large block or hole
- compaction is possible only if relocation is dynamic

# non-contiguous allocation
- if size of processes vary a lot, it is very difficult to put them efficiently in memory
- in memory allocation, the best candidate to serve as a container is the **page**
    - a page is a size of physical memory manipulated as a unit and it often corresponds to a block in the hard disk
- when memory is divided up into pages, it is no longer necessary that consecutive pages be allocated for a process — this is **non-contiguous allocation**
    - the same concept is used in networking, to break up a message into fixed sized packets

## paging
- physical address space may not be contiguous, though logical address space may still be contiguous
- in paging mechanism, physical memory is divided into fixed-sized blocks called **frames**
    - the size of a frame is always power of 2 (normally between 512 bytes and 8,192 bytes)
- logical memory is divided into blocks of same size as frames, called **pages**
- OS keeps track of all the free frames in a frame table
- to run a program of size of n pages, allocate n free frames in memory and load the program into those frames
- since frames are scattered around, a **page table** is used to translate logical address to physical address

- since each logical address generated by CPU needs to be mapped or translated into a physical address in memory, this translation must be very efficient— this should be done with hardware support
- the logical address is divided into two parts
    
    
    | page number (p) | it is used as an index into a page table to look up for base address of each frame in physical memory |
    | --- | --- |
    | page offset (d) | it is added (or appended) to the base address to form the physical memory address |
- assume that the logical address space is of size 2m and each page (and frame) has a size of 2n
    - **logical address** has a size of m bits
    - **page number p** contains m−n bits
    - **page offset d** contains n bits
- paging suffers from internal fragmentation
    
# page table implementation

- the **page table** is the key for translation from logical to physical address for a process
- there is one page table for each process and it is kept in the main memory
- a hardware register, called **page-table base register** (PTBR), points to the page table for a process
- context switching is fast, since only one register needs to be changed for a newly scheduled process
- **every data/instruction access requires two memory accesses**: one for page table and one for data / instruction
    - this extra memory access to page table is expensive but is solved by a hardware cache called **translation look-aside buffer (TLB)** to store recently translated logical page number

## translation look-aside buffer

- made up of high-speed associative memory (a form of cache) that allows concurrent search for a tag— the drawback is that the **hardware cost is high**
- TLB is inserted between the translation path from a page number to a frame number— the **tag** is the page number p, and the **value** is the frame number f
    - we first look up the TLB to for the existence of p and return the value of f; if that is successful, we call it a TLB hit, otherwise, that is a TLB miss and so we will look up the page table indexed by p to get f

- for a TLB hit, the data access cost is only 1 + c, where c is the cost of cache access and c << 1

- for a TLB miss, the data access cost is 2 + c
    - after the miss, the new pair (p, f) will be inserted into TLB for future use
- without TLB, **data access cost is 2**
- let the TLB hit ratio be h (0 ≤ h ≤ 1)— this hit ratio depends on the number of entries (size) of TLB
- effective memory access time is the expected time to perform a memory access
    - translation time = h x cache access time + (1 – h) x (cache access time + memory access time) = cache access time (1 – h) x memory access time
    - effective access time = translation time + memory access time = cache access time + (2 – h) x memory access time

### example

- memory access time = 100 ns
- cache access time = 20 ns
- effective access time = 20 + (2 – h) x 100 = 220 – 100h
    - if TLB hit ratio is 80%, effective access time = 140 ns
    - if TLB hit ratio is 90%, effective access time = 130 ns
    - if TLB hit ratio is 99%, effective access time = 121 ns
- access latency for fast L1 cache is only 1 ns
    - access times would be 121, 111, 102 ns respectively

### example

- assume that a logical address is of 32 bits, that a page and a frame are of size 4KB, and that the main memory is of size 64MB
    - m=32 (length of full logical address)
    - n=12 (page and frame size of 4K = 212, length of offset d)
    - m-n=20 (length of page number p)
- there will be 64M/4K = 16384 = 214 frames, so 14 bits are needed to store the frame number (length of f=14)
- each page table entry therefore needs 2 bytes for storing this frame number

- if a small-sized process has a size of 256K, it would need 256K/4K = 64 entries in the page table, i.e., it needs a page table of size 128 bytes, i.e. 1 page for the page table

- if a medium-sized process has a size of 8M, it would need 8M/4K = 2K entries in the page table, i.e., it needs a page table of size 4K bytes, just fit inside 1 page. So 8M is the maximum process size for a small page table

### example

- now assume logical address of 32 bits, page and frame size of 4KB, and main memory of size 512MB
    - m=32 and n=12 (length of d) so m -n=20 (length of p)
    - there will be 512M/4K = 131072 frames, so 17 bits are needed to store the frame number (length of f =17)
- as it is more than 2 bytes, each page table entry needs 4 bytes (17 bits for frame number, plus other information)
- if a huge process uses up the whole address space (defining many big arrays), it could have 2 20 entries in the page table
    - the size of the page table will then be 220 x 4 bytes = 4MB
- we could not store this large page table in consecutive block of memory, so we need to find a way to handle this table
- three possible solutions:
    - hierarchical paging
    - hashed page table
    - inverted page table

## hierarchical paging

- break up page table to be stored into multiple pages— in other words, break up logical address space into multiple page tables
- a logical address (on 32-bit machine with 4KB page size) is divided into:
    - a **page number** consisting of 20 bits
    - a **page offset** consisting of 12 bits
- page table is itself paged, page number is further divided into:
    - a 10-bit second level page number
    - a 10-bit second level page offset
- we call the second level page table the **outer page table**
    - you could have a second outer page table if needed
- here p1 is an index into the outer page table and p2 is the displacement within the page of the outer page table— note that the effective memory access time will increase for accessing several page tables

# memory protection

- a program may not use up all pages in page table since some pages in may be **read-only** (e.g. program text)
- memory protection is implemented by associating one or more protection bits with each page, e.g., we may attach a valid-invalid bit to each page table entry
    - “**valid**” indicates that the page is in process’ logical address space and is a legal page
    - “**invalid**” indicates that the page is not in logical address space— accessing it will generate a trap to OS
- a **hardware page-table length register** (PTLR) is often used to check for validity of a logical address

## shared pages

- use of **paging** allows easy sharing of program code with private data
    - one copy of read-only code is shared among processes (e.g. editor)
- each process keeps a separate copy of its private data
    - private data can appear anywhere in the logical address space of a process

# segmentation

- users do not see pages, but they see segments for their programs
    - a **program** consists of a collection of segments
    - a **segment** is a logical unit such as main program, procedures, functions, methods, objects, local variables, global variables, common block, stack, library, symbol table
- segmentation is the memory management scheme that supports user view of memory with segments
    - segments are given segment numbers
    - each segment is mapped to specific part of physical memory via **segment table**

- logical address has two parts
    - <segment-number, offset>
- segment table maps logical into physical addresses
- each segment table entry has
    
    
    | base | contains segment starting physical address in memory |
    | --- | --- |
    | limit | specifies length of the segment |
    | valid bit and access privilege bits | for protection |
    - since segments vary in length, memory allocation is similar to contiguous dynamic storage-allocation problem— segmentation suffers from **external fragmentation**

- **segment-table base register (STBR)** points to the segment table’s location in memory

- **segment-table length register (STLR)** indicates the number of segments used by a program

## shared segments

- use of segments also allows easy sharing of program code or shared data across processes— page sharing is easier, since all pages are of the same size, at fixed boundary, but segment sharing needs more works
- an example of two processes sharing data with 4K memory
    - P1 has three segments: S0 to S2
    - P2 also has three segments: S0 to S2
    - P1-S2 and P2 -S1 refer to the same shared segment
  
